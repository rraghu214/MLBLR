# Session 3 Notes...

1. The Checkerboard issue
2. Dilated Convolution
3. Fractionally Shreded Convolution or Deconvolution
4. Depthwise Convolution
5. Seperable Convolution - Winograd
6. Grouped Convolution
7. Dropout
8. Residual Blocks
9. Max Pooling
10. 1 X 1 Convolution

##### Architectural Basics

1. Data Augumentation
2. Initialization --> Random
3. Activation Function --> Sigmoid, ReLu
4. Loss Function --> Cross Entropy Loss, Custom Loss Function
5. Regularization --> Drop out, Label Smoothing
6. Normalization
7. Optimizer --> SGD, Adam
8. Convolutions --> Usual (3 X 3), 1 X 1, CX1   1 X C Convolution, Grouped, Depthwise, Max Pooling
9. Other Arch Decisions --> Average Pooling, Skip Connections